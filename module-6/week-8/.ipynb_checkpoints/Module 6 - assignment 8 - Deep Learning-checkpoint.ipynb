{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd0256d",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this exercise, a neural network will be created. This will be done for the famous MNIST dataset, which contains thousands of images with the a letter from 0-9 and their corresponding label.\n",
    "\n",
    "The neural network will be created based on object oriented programming. Meaning, that a class will be created for the architecture of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02eefc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install idx2numpy and torch if you haven't already\n",
    "#%pip install idx2numpy\n",
    "#%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80db7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import idx2numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2b4aa1",
   "metadata": {},
   "source": [
    "# Importing the data and making it ready\n",
    "In this chapter, the data will be imported and prepared for training and testing the neural network. The data is retrieved from the following website: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d18066a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the datasets as ubyte files and transform them into 2/3-dimensional numpy arrays\n",
    "train_images = idx2numpy.convert_from_file(\"train-images.idx3-ubyte\")\n",
    "train_labels = idx2numpy.convert_from_file(\"train-labels.idx1-ubyte\")\n",
    "test_images = idx2numpy.convert_from_file(\"t10k-images.idx3-ubyte\")\n",
    "test_labels = idx2numpy.convert_from_file(\"t10k-labels.idx1-ubyte\")\n",
    "\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e301d46",
   "metadata": {},
   "source": [
    "## Making the data ready\n",
    "In this chapter, the data will be prepared for the neural network. First, the data will be made ready for the `Dataloader` function. This will be done by creating a class `Data`, which inherits the Data `torch.utils.data.Dataset` properties. Then, the data will be scaled so that it ranges from 0-1, instead of 0-255. And finally the datasets will be transformed into a DataLoader, which will be used to train and test the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf97bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new class which makes the data ready for the DataLoader.\n",
    "# This is done by inheriting the torch.utils.data.Dataset properties\n",
    "class Data(Dataset):\n",
    "    # init function which takes X_train and y_train data\n",
    "    def __init__(self, X_train, y_train):\n",
    "        # need to convert float64 to float32 else \n",
    "        # will get the following error\n",
    "        # RuntimeError: expected scalar type Double but found Float\n",
    "        self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "        # need to convert float64 to Long else \n",
    "        # will get the following error\n",
    "        # RuntimeError: expected scalar type Long but found Float\n",
    "        self.y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "        self.len = self.X.shape[0]\n",
    "  \n",
    "    # Function to retrieve the value of X and y based on the index\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    # Function to retrieve the length of the dataset\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec76975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which scales the input data into 0 and 1\n",
    "def min_max_scaled(dataset):\n",
    "    # Manually scale the data between 0 and 1\n",
    "    data = ((dataset - dataset.min()) / dataset.max() - dataset.min())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aee6506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ardejong\\AppData\\Local\\Temp/ipykernel_21676/2323167276.py:13: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:178.)\n",
      "  self.y = torch.from_numpy(y_train).type(torch.LongTensor)\n"
     ]
    }
   ],
   "source": [
    "# Scale the data so that is has a range between 0 and 1\n",
    "# This is done manually to avoid for looping\n",
    "train_images_scaled = min_max_scaled(train_images)\n",
    "test_images_scaled = min_max_scaled(test_images)\n",
    "\n",
    "# Define the train and test set using the Data class we created earlier\n",
    "trainset = Data(train_images_scaled, train_labels)\n",
    "testset = Data(test_images_scaled, test_labels)\n",
    "\n",
    "# Create DataLoaders using DataLoader class: trainLoader, testLoader\n",
    "trainloader = DataLoader(trainset, batch_size = 10,\n",
    "                        shuffle = True, num_workers=0)\n",
    "testloader = DataLoader(testset, batch_size = 10,\n",
    "                        shuffle = False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15c95c",
   "metadata": {},
   "source": [
    "# Neural network\n",
    "In this chapter, the neural network will be created, trained and tested. For the neural network, the architecture of the model looks like:\n",
    "- An input layer with 28 * 28 * 1 nodes: 784\n",
    "- A 1st hidden layer with 14 * 14 nodes: 196\n",
    "- A 2nd hidden layer with 7 * 7 nodes: 28\n",
    "- An output layer with ten nodes\n",
    "\n",
    "This architecture is chosen because the shape of a image is 28 * 28 * 1. After the input layer, we devide the shape in half, so the 1st hidden layer would be 14 * 14. This is done for the 2nd layer as well. This is done, so that splitting is halved each layer.\n",
    "\n",
    "There are 10 output nodes, since there are 10 possible outputs for the labels: a number between 0 and 9.\n",
    "\n",
    "The metric to measure our performance is `accuracy`. This metric is chosen because it fits our machine learning type the best: multi-classification. Metrics like loss is more suitable for regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33622254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network using OOP: Net\n",
    "# It inherits the torch.nn.Module properties\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):    \n",
    "    # Define all the parameters of the net\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Define the layers for the neural network\n",
    "        self.fc1 = nn.Linear(28 * 28 * 1, 14 * 14)\n",
    "        self.fc2 = nn.Linear(14 * 14, 28)\n",
    "        self.fc3 = nn.Linear(28, 10)\n",
    "\n",
    "    def forward(self, x):   \n",
    "    # Do the forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1c99ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Net(\n",
      "  (fc1): Linear(in_features=784, out_features=196, bias=True)\n",
      "  (fc2): Linear(in_features=196, out_features=28, bias=True)\n",
      "  (fc3): Linear(in_features=28, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = Net()\n",
    "\n",
    "# Define loss and optimzer functions\n",
    "# Choose learning rate of 3e-4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da4b5b",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "In this chapter, the model will be trained. For the training, we chose 15 epochs, because during development, we found out that the accuracy will go down if we chose more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ea7fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy epoch 1: 87.787%\n",
      "Accuracy epoch 2: 94.000%\n",
      "Accuracy epoch 3: 95.458%\n",
      "Accuracy epoch 4: 96.460%\n",
      "Accuracy epoch 5: 97.035%\n",
      "Accuracy epoch 6: 97.465%\n",
      "Accuracy epoch 7: 97.803%\n",
      "Accuracy epoch 8: 98.063%\n",
      "Accuracy epoch 9: 98.297%\n",
      "Accuracy epoch 10: 98.450%\n",
      "Accuracy epoch 11: 98.598%\n",
      "Accuracy epoch 12: 98.710%\n",
      "Accuracy epoch 13: 98.810%\n",
      "Accuracy epoch 14: 98.950%\n",
      "Accuracy epoch 15: 99.022%\n"
     ]
    }
   ],
   "source": [
    "# Train the data using a for loop\n",
    "# Define number of epochs\n",
    "epochs = 15\n",
    "\n",
    "accuracies = []\n",
    "for epoch in range(epochs):\n",
    "    # Initialize total and correct to 0\n",
    "    # These will be used later\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Put each image into a vector\n",
    "        inputs = inputs.view(-1, 28 * 28)\n",
    "        \n",
    "        # set optimizer to zero grad to remove previous epoch gradients\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # Apply forward propagation using the model\n",
    "        # Get loss function for data\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, outputs = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Add the total to the total variable\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Add the correct to the correct variable\n",
    "        correct += (outputs == labels).sum()\n",
    "        \n",
    "        # backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # optimize\n",
    "        optim.step()\n",
    "    \n",
    "    # Print the accuracy of the epoch\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f\"Accuracy epoch {epoch + 1}: {accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b0a889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the neural network is: 98.020%\n"
     ]
    }
   ],
   "source": [
    "# Set the model in eval mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize total and correct to 0\n",
    "# These will be used later\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "# Predict for each row in the test set and see if there correct\n",
    "for data in testloader:\n",
    "    inputs, labels = data\n",
    "    \n",
    "    # Put each image into a vector\n",
    "    inputs = inputs.view(-1, 28 * 28 * 1)\n",
    "    \n",
    "    # Do the forward pass and get the predictions\n",
    "    outputs = model(inputs)\n",
    "    _, outputs = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Add the total to the total variable\n",
    "    total += labels.size(0)\n",
    "    \n",
    "    # Add the correct to the correct variable\n",
    "    correct += (outputs == labels).sum()\n",
    "    \n",
    "    \n",
    "accuracy = (correct / total) * 100   \n",
    "print(f'The testing set accuracy of the neural network is: {accuracy:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99cde25",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c019d3",
   "metadata": {},
   "source": [
    "Based on the accuracy of both the train and test set, we can conclude that the model performs really great. For the train set, right on the first epoch, we have an accuracy of 87.787%, and 99.022% after the final epochs. For the test set, we have an accuracy of 98.020%. Based on the fact that the accuracies from the train and test set only differ around 1 percent, we can conclude that the model is well trained (neither over- or undertrained)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
