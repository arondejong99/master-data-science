{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c9f34d",
   "metadata": {},
   "source": [
    "# Data cleaning: bank.csv\n",
    "In this exercise, we will clean a dataset. The following cleaning techniques will be used:\n",
    "- Convert certain columns to appropriate types\n",
    "- Dealing with outliers (values that deviate from the rest of the data distribution)\n",
    "- Discarding unnecessary features (columns that are not useful)\n",
    "- Dealing with missing values in both rows and columns\n",
    "- Dealing with categories that need to be remapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d738d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb48f13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv(\"bank-full.csv\", sep = ';')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3389918",
   "metadata": {},
   "source": [
    "## Convert data to the right data types\n",
    "The following columns have to be converted:\n",
    "- job: from object to category\n",
    "- marital: from object to category\n",
    "- education: from object to category\n",
    "- default: from object to category\n",
    "- housing: to category\n",
    "- loan: to category\n",
    "- contact: category\n",
    "- poutcome: category\n",
    "- y: category\n",
    "- month: category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "439c7ed8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job          category\n",
       "marital      category\n",
       "education    category\n",
       "default        object\n",
       "housing        object\n",
       "loan           object\n",
       "contact        object\n",
       "poutcome       object\n",
       "y              object\n",
       "month          object\n",
       "default        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of columns to convert to\n",
    "# Categories\n",
    "cols = ['job', 'marital', 'education', 'default', 'housing',\n",
    "       'loan', 'contact', 'poutcome', 'y', 'month', 'default']\n",
    "\n",
    "# Convert each column to a category\n",
    "#df[cols] = df[cols].astype('category')\n",
    "    \n",
    "df[cols].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783c674",
   "metadata": {},
   "source": [
    "## Dealing with outliers\n",
    "The following columns can have possible outliers and maybe need to be dealt with.\n",
    "- age\n",
    "- balance\n",
    "- day\n",
    "- campaign\n",
    "- pdays\n",
    "- previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f711e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['age', 'balance', 'day', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "for col in cols:\n",
    "    print(df[col].describe())\n",
    "# campaign, pdays, previous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee82f53",
   "metadata": {},
   "source": [
    "Based on the results, the columns campaign, pdays and previous have huge outliers and need to be dealt with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7e4b3c",
   "metadata": {},
   "source": [
    "### Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with campaign column\n",
    "# Plot a histogram\n",
    "sns.histplot(df['campaign'], bins = 10)\n",
    "\n",
    "# Most campagnes are between 0 and 10. Some outliers are visible between 10 and 30 but after that, the amount of campaigns are\n",
    "# too outlied. To fix this, the data will remove with campaigns higher than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef92025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the campaign column\n",
    "# Replace each value higher than 10 by the value devided by 10\n",
    "# Round it by zero\n",
    "campaign = df['campaign']\n",
    "df2 = df.loc[campaign <= 10]\n",
    "\n",
    "sns.histplot(df2['campaign'], bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc97c05",
   "metadata": {},
   "source": [
    "### Pdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e233707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pdays demonstrates the number of days that passed by after the client was last contacted from a previous campaign\n",
    "# If the value is -1 then client was not previously contacted\n",
    "# This means that the value of -1 needs to be replace with NaN\n",
    "\n",
    "print(df2['pdays'].describe())\n",
    "\n",
    "# Replacing the values with NaN\n",
    "df2.loc[df2['pdays'] < 0, 'pdays'] = np.nan\n",
    "\n",
    "print(df2['pdays'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbed6d7f",
   "metadata": {},
   "source": [
    "## Discarding unnecessary features/columns\n",
    "In this chapter, we'll check for the columns that have binary outputs if the outputs are both represented or not. If a binary \n",
    "column is barely/not represented, it will be removed. Each column will be shown with a histogram to see if both values have a representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8ad3c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binaries = [x for x in df.columns if len(df[x].unique()) == 2]\n",
    "\n",
    "print(binaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7bf59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.histplot(df[binaries[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa695d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[binaries[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd7582",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[binaries[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e964041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[binaries[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e3fee",
   "metadata": {},
   "source": [
    "Notes: based on the subplots, we can see that the 'default' column with value yes is not good represented. That's why the column will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd5723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove default column\n",
    "df2 = df2.drop(['default'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5570ab1",
   "metadata": {},
   "source": [
    "## Dealing with missing values in both rows and columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()\n",
    "\n",
    "# Based on the info function, we can see that the pdays column now only has 8233 non-null values.\n",
    "# The best option is to remove the pdays column. \n",
    "\n",
    "df2 = df2.dropna(axis = 1)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa66aea",
   "metadata": {},
   "source": [
    "## Remapping categories\n",
    "The following columns need to be remapped:\n",
    "- job: remove . from admin and change blue-collar to manual-labor\n",
    "- remap every binary column to 1 (yes) or 0 (no)\n",
    "- month: remap from str to num (1, 2, 3 instead of jan, feb, mar etc.)\n",
    "\n",
    "### Job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique jobs\n",
    "jobs = df2['job'].unique()\n",
    "    \n",
    "# change admin. to administrator and services to pink-collar\n",
    "# Change the datatype to str in order to change the value of job\n",
    "df2['job'] = df2['job'].astype('str')\n",
    "df2.loc[df2['job'] == 'admin.', 'job'] = 'administrator'\n",
    "df2.loc[df2['job'] == 'services', 'job'] = 'manual-labor'\n",
    "\n",
    "df2['job'] = df2['job'].astype('category')\n",
    "\n",
    "for job in jobs:\n",
    "    print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce76d30b",
   "metadata": {},
   "source": [
    "### Binary columns\n",
    "In the dataset, each binary column has a string value of \"yes\" and \"no\". Those values will be replaced\n",
    "with True or False. Also, the data type will be changed to boolean. \n",
    "The binary columns are:\n",
    "- housing\n",
    "- loan\n",
    "- y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1b34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create mapping columns\n",
    "columns = ['housing', 'loan', 'y']\n",
    "\n",
    "# Create mapping list to change the values to\n",
    "mapping = {\"yes\": True, \"no\": False}\n",
    "\n",
    "# Remap the columns\n",
    "for col in columns:\n",
    "    df2[col] = df2[col].replace(mapping)\n",
    "    df2[col] = df2[col].astype('boolean')\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d554e2",
   "metadata": {},
   "source": [
    "### Month\n",
    "The month column is created as jan, feb, mar etc. It needs to be remapped to the numbers of the month (1 to 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df329ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dict to use for rempaping\n",
    "mapping = {\"jan\": 1, \"feb\": 2, \"mar\": 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8,\n",
    "          'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
    "\n",
    "# Remap the month column\n",
    "df2['month'] = df2.month.replace(mapping)\n",
    "\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e2258",
   "metadata": {},
   "source": [
    "## Exporting the data\n",
    "The last step is to export the dataframe to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c936695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the filename based on the current date\n",
    "date = str(dt.now().strftime('%d-%m-%Y'))\n",
    "filename = 'bank-data-' + date + '.csv'\n",
    "\n",
    "# Export the file\n",
    "df2.to_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
